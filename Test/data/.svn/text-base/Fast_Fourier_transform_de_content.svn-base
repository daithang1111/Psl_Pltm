<input type="hidden" value="d41d8cd98f00b204e9800998ecf8427e" name="wpAutoSummary" /><input type="hidden" value="0" name="oldid" /><input type="hidden" value="text/x-wiki" name="format" /><input type="hidden" value="wikitext" name="model" /><div class="wikiEditor-oldToolbar" style="display:none;"><div id="toolbar"></div></div><textarea tabindex="1" accesskey="," id="wpTextbox1" cols="80" rows="25" style="" lang="de" dir="ltr" name="wpTextbox1">Eine '''schnelle Fourier-Transformation''' ({{EnS|fast Fourier transform}}, daher meist '''FFT''' abgekÃ¼rzt) ist ein [[Algorithmus]] zur effizienten Berechnung der Werte einer [[Diskrete Fourier-Transformation|diskreten Fourier-Transformation]] (DFT). Bei solchen Algorithmen handelt es sich um [[Teile und herrsche (Informatik)|Teile-und-herrsche]]-Verfahren. Im Gegensatz zur direkten Berechnung verwendet eine schnelle Fourier-Transformation zuvor berechnete Zwischenergebnisse und spart arithmetische Rechenoperationen ein. Das bekannteste Verfahren wird [[James Cooley]] und [[John W. Tukey]] zugeschrieben, die es 1965 verÃ¶ffentlichten. Genau genommen wurde eine Form des Algorithmus bereits 1805 von [[Carl Friedrich GauÃŸ]] entworfen, der ihn zur Berechnung der Flugbahnen der [[Asteroid]]en [[(2) Pallas]] und [[(3) Juno]] verwendete. Zum ersten Male publiziert wurde eine Variante des Algorithmus von [[Carl Runge]] im Jahre 1903 und 1905. DarÃ¼ber hinaus wurden eingeschrÃ¤nkte Formen des Algorithmus mehrfach vor Cooley und Tukey entwickelt, so z.&amp;nbsp;B. von [[Irving John Good]] (1960). Nach Cooley und Tukey hat es darÃ¼ber hinaus zahlreiche VerbesserungsvorschlÃ¤ge und Variationen gegeben, so etwa von [[Georg Bruun]], [[C. M. Rader]] und [[Leo I. Bluestein]].

Analog gibt es fÃ¼r die diskrete inverse Fourier-Transformation einen ''schnellen'' Algorithmus (inverse FFT â€“ [[iFFT]]). Es kommen bei der iFFT identische Algorithmen mit anderen Koeffizienten in der Berechnung zur Anwendung.

== Informelle Beschreibung des Algorithmus (Cooley und Tukey) ==
Der Algorithmus von Cooley und Tukey ist ein klassisches [[Teile und herrsche (Informatik)|Teile-und-herrsche]]-Verfahren. Voraussetzung fÃ¼r seine Anwendung ist, dass die Anzahl der [[StÃ¼tzstellendarstellung|StÃ¼tzstellen]] bzw. Abtastpunkte eine Zweierpotenz ist. Da die Anzahl solcher Punkte im Rahmen von Messverfahren jedoch im Allgemeinen frei gewÃ¤hlt werden kann, handelt es sich dabei nicht um eine gravierende EinschrÃ¤nkung. 

Die Idee hinter dem Algorithmus ist es nun, dass die Berechnung einer DFT der GrÃ¶ÃŸe ''2n'' nun zunÃ¤chst in zwei Berechnungen der DFT der GrÃ¶ÃŸe ''n'' aufgeteilt â€“ den Vektor mit den EintrÃ¤gen der geraden bzw. der ungeraden Indizes â€“ und die beiden Teilergebnisse nach der Transformation wieder zu einer Fouriertransformation der GrÃ¶ÃŸe ''2n'' zusammengefÃ¼gt werden kÃ¶nnen. 

Da die Berechnung einer DFT der halben LÃ¤nge nur ein Viertel der komplexen Multiplikationen und Additionen der originalen DFT benÃ¶tigt, und je nach LÃ¤nge des Ausgangsvektors diese Vorschrift mehrfach hintereinander anwendbar ist, erlaubt die [[Rekursion|rekursive]] Anwendung dieser Grundidee schlieÃŸlich eine Berechnung in [[Landau-Symbole#Definition|&lt;math>\mathcal{O}(n \log n)&lt;/math>]] Zeit; Zur Einsparung von [[Trigonometrie|trigonometrischen]] Rechenoperationen kÃ¶nnen bei der FFT zusÃ¤tzlich die Eigenschaften der [[Einheitswurzel]]n aus der Fouriermatrix ausgenutzt werden.

== Formelle Beschreibung des Algorithmus (Cooley und Tukey) ==
ZunÃ¤chst sei in Erinnerung gerufen, dass die [[Diskrete Fourier-Transformation|diskrete Fouriertransformation]] (im Folgenden DFT genannt) der GrÃ¶ÃŸe ''2n'' durch folgende Formel definiert ist:

:&lt;math>f_m =  \sum_{k=0}^{2n-1} x_k \;e^{-\frac{2\pi i}{2n} mk }
\qquad
m = 0,\dots,2n-1. &lt;/math>

Notieren wir die EintrÃ¤ge zu geraden Indizes als 
:''x'&lt;sub>0&lt;/sub> = x&lt;sub>0&lt;/sub>'', ''x'&lt;sub>1&lt;/sub> = x&lt;sub>2&lt;/sub>, â€¦, x'&lt;sub>n-1&lt;/sub> = x&lt;sub>2n-2&lt;/sub>'' 
und bezeichnen deren Transformierte nach DFT der GrÃ¶ÃŸe ''n'' mit 
:''f'&lt;sub>0&lt;/sub>, â€¦, f'&lt;sub>n-1&lt;/sub>''; 
die EintrÃ¤ge zu ungeraden Indizes notieren wir entsprechend als 
:''x"&lt;sub>0&lt;/sub> = x&lt;sub>1&lt;/sub>, x"&lt;sub>1&lt;/sub> = x&lt;sub>3&lt;/sub>, â€¦, x"&lt;sub>n-1&lt;/sub> = x&lt;sub>2n-1&lt;/sub>'' 
und bezeichnen deren Transformierte nach DFT der GrÃ¶ÃŸe ''n'' mit 
:''f"&lt;sub>0&lt;/sub>, â€¦, f"&lt;sub>n-1&lt;/sub>''. 
Dann folgt:

:&lt;math>
\begin{align}

f_m &amp; =   \sum_{k=0}^{n-1} x_{2k  } e^{-\frac{2\pi i}{2n} m(2k  )}
       +  \sum_{k=0}^{n-1} x_{2k+1} e^{-\frac{2\pi i}{2n} m(2k+1)} \\[0.5em]
    &amp; =                         \sum_{k=0}^{n-1} x' _k e^{-\frac{2\pi i}{n} mk}
       +  e^{-\frac{\pi i}{n}m} \sum_{k=0}^{n-1} x''_k e^{-\frac{2\pi i}{n} mk}\\[0.5em]
&amp; =  \begin{cases}
 f'_m     +  e^{-\frac{\pi i}{n} m   } f''_m     &amp; \text{ falls } m&lt;n \\[0.5em]
 f'_{m-n} -  e^{-\frac{\pi i}{n}(m-n)} f''_{m-n} &amp; \text{ falls } m \geq n 
\end{cases}
\end{align}
&lt;/math>

== Mathematische Beschreibung (allgemeiner Fall) ==
In der Mathematik wird die schnelle diskrete Fouriertransformation in einem wesentlich allgemeineren Kontext behandelt:

Sei &lt;math>R&lt;/math> ein [[KommutativitÃ¤t|kommutativer]] [[unitÃ¤rer Ring]]. In &lt;math>R&lt;/math> sei die Zahl &lt;math>2=1+1&lt;/math> eine [[Einheit (Mathematik)|Einheit]] (d. h. invertierbar); ferner sei &lt;math>w \in R&lt;/math> eine &lt;math>2^n&lt;/math>-te Einheitswurzel mit &lt;math>w^{2^{n-1}}=-1&lt;/math>. Zum Beispiel ist im [[Restklassenring]] 
:&lt;math>R=\Z/N\Z&lt;/math> mit &lt;math> N=2^{d2^n}+1&lt;/math>, &lt;math>d,n\in\N&lt;/math>, ''d'' ungerade (das ist gleichbedeutend mit der Forderung â€žteilerfremd zu &lt;math>2^n&lt;/math>â€œ), 
das Element &lt;math>w=2^{2d}&lt;/math> eine solche Einheitswurzel, die entsprechende FFT wird im [[SchÃ¶nhage-Strassen-Algorithmus]] verwendet.

Dann lÃ¤sst sich im [[Modul (Mathematik)|Modul]] &lt;math>R^{2^n}&lt;/math> zu &lt;math>a\in R^{2^n}&lt;/math> die diskrete Fouriertransformierte &lt;math>\hat a&lt;/math> mit
:&lt;math>\hat a_k = \sum_{j=0}^{2^n-1} a_j\cdot w^{j\cdot k}\qquad (k=0,\ldots, 2^n-1)&lt;/math>
wie folgt optimiert berechnen:

ZunÃ¤chst stellen wir die Indizes &lt;math>j&lt;/math> und &lt;math>k&lt;/math> wie folgt dual dar:
:&lt;math>k = \sum_{\nu=0}^{n-1} k_\nu 2^\nu,\quad j = \sum_{\nu=0}^{n-1} j_\nu 2^{n-1-\nu}&lt;/math>.

Damit haben wir folgende Rekursion:
:&lt;math> A_0(j_0,\ldots,j_{n-1}) = a_j\qquad (j=0,\ldots,2^n-1)&lt;/math>,
:&lt;math>A_{r+1}(k_0,\ldots, k_r, j_{r+1},\ldots,j_{n-1}) = \sum_{j_r=0}^1 A_r(k_0,\ldots,k_{r-1},j_r,\ldots,
 j_{n-1})\cdot w^{j_r\cdot 2^{n-1-r}\cdot (k_r 2^r+\ldots+k_0 2^0)}&lt;/math>.

Wegen
:&lt;math>A_n(k_0,\ldots,k_{n-1}) = \hat a_k&lt;/math>
erhalten wir hieraus die diskrete Fouriertransformierte &lt;math>\hat a\in R^{2^n}&lt;/math>.

== KomplexitÃ¤t ==
Diese ''klassische'' Variante der FFT nach Cooley und Tukey ist im Gegensatz zur [[Diskrete Fourier-Transformation|DFT]] nur durchfÃ¼hrbar, wenn die LÃ¤nge des Eingangsvektors einer Zweierpotenz entspricht. Die Anzahl der [[Abtastung (Signalverarbeitung)|Abtastpunkte]] kann also beispielsweise 1, 2, 4, 8, 16, 32 usw. betragen. Man spricht hier von einer Radix-2-FFT. Andere LÃ¤ngen sind mit den unten angefÃ¼hrten alternativen Algorithmen mÃ¶glich.

Aus obiger Rekursion ergibt sich folgende Rekursionsgleichung fÃ¼r die Laufzeit der FFT:
:&lt;math> T \left( N \right)= 2T \left( N/2 \right) + f (N)&lt;/math>
Hierbei beschreibt der Term &lt;math>f(N)&lt;/math> den Aufwand, um die Ergebnisse mit einer Potenz der Einheitswurzel zu multiplizieren und die Ergebnisse zu addieren. Es werden ''N'' Paare von Zahlen addiert und ''N/2'' Zahlen mit Einheitswurzeln multipliziert. Insgesamt ist f(N) also linear beschrÃ¤nkt:
:&lt;math> T \left( N \right)= 2T \left( N/2 \right) + \mathcal{O} \left(N\right)&lt;/math>
Mit dem [[Master-Theorem]] ergibt sich eine Laufzeit von:
:&lt;math> T \left( N \right)=\mathcal{O}(N \cdot \log(N))&lt;/math>
Die Struktur des Datenflusses kann durch einen [[Schmetterlingsgraph]]en beschrieben werden, der die Reihenfolge der Berechnung festlegt.

== Implementierung als rekursiver Algorithmus ==
Die direkte Implementierung der FFT in [[Pseudocode]] nach obiger Vorschrift besitzt die Form eines [[Rekursion|rekursiven Algorithmus]]: 
* Das Feld mit den Eingangswerten wird einer Funktion als Parameter Ã¼bergeben, die es in zwei halb so lange Felder (eins mit den Werten mit geradem und eins mit den Werten mit ungeradem Index) aufteilt.
* Diese beiden Felder werden nun an neue Instanzen dieser Funktion Ã¼bergeben.
* Am Ende gibt jede Funktion die FFT des ihr als Parameter Ã¼bergebenen Feldes zurÃ¼ck. Diese beiden FFTs werden nun, bevor eine Instanz der Funktion beendet wird, nach der oben abgebildeten Formel zu einer einzigen FFT kombiniert - und das Ergebnis an den Aufrufer zurÃ¼ckgegeben.
Dies wird nun fortgefÃ¼hrt, bis das Argument eines Aufrufs der Funktion nur noch aus einem einzigen Element besteht (Rekursionsabbruch): Die FFT eines einzelnen Wertes ist (er besitzt sich selbst als Gleichanteil, und keine weiteren Frequenzen) er selbst. Die Funktion, die nur noch einen einzigen Wert als Parameter erhÃ¤lt, kann also ganz ohne Rechnung die FFT dieses Wertes zurÃ¼ckliefern â€“ die Funktion, die sie aufgerufen hat, kombiniert die beiden jeweils 1 Punkt langen FFTs, die sie zurÃ¼ckerhÃ¤lt, die Funktion, die diese wiederum aufgerufen hat, die beiden 2-Punkte-FFTs, und so weiter.

&lt;math>\mathrm{function}\ \operatorname{fft}(n,\vec f): &lt;/math>

:&lt;math>\mathrm{if}\ (n = 1)  &lt;/math>

::&lt;math>\mathrm{return}\ \vec f  &lt;/math>

:&lt;math>\mathrm{else} \ &lt;/math>

::&lt;math>\vec g = \operatorname{fft}\left(\tfrac{n}{2},( f_0, f_2, \ldots ,f_{n-2})\right) &lt;/math>

::&lt;math>\vec u = \operatorname{fft}\left(\tfrac{n}{2}, (f_1, f_3, \ldots ,f_{n-1})\right) &lt;/math>

::&lt;math>\mathrm{for} \ k = 0 \ \mathrm{to} \ \tfrac{n}{2}-1 &lt;/math>

:::&lt;math>
\begin{align}
c_k       = g_k + u_k \cdot e^{-2 \pi i k/n} \\
c_{k+n/2} = g_k - u_k \cdot e^{-2 \pi i k/n} 
\end{align}
&lt;/math>

::&lt;math>\mathrm{return}\ \vec c&lt;/math>

Der Geschwindigkeitsvorteil der FFT gegenÃ¼ber der DFT kann anhand dieses Algorithmus gut abgeschÃ¤tzt werden:
* Um die FFT eines &lt;math>2^N&lt;/math> Elemente langen Vektors zu berechnen, sind bei Verwendung dieses Algorithmus ''n'' Rekursionsebenen nÃ¶tig. Dabei verdoppelt sich in jeder Ebene die Anzahl der zu berechnenden Vektoren - wÃ¤hrend sich deren LÃ¤nge jeweils halbiert, so dass am Ende in jeder bis auf die letzte Rekursionsebene genau &lt;math>n&lt;/math> komplexe Multiplikationen und Additionen notwendig sind. Die Gesamtzahl der Additionen und Multiplikationen betrÃ¤gt also &lt;math>N\cdot2^N&lt;/math>
* Im Gegensatz benÃ¶tigt die DFT fÃ¼r denselben Eingangsvektor &lt;math>(2^N )^2&lt;/math> komplexe Multiplikationen und Additionen.

== Implementierung als nichtrekursiver Algorithmus ==
Die Implementierung eines rekursiven Algorithmus ist im Regelfall vom Ressourcenverbrauch her nicht ideal, da die vielen dabei notwendigen Funktionsaufrufe Rechenzeit und Speicher fÃ¼r das Merken der RÃ¼cksprungadressen benÃ¶tigen. In der Praxis wird daher meist ein nichtrekursiver Algorithmus verwendet, der gegenÃ¼ber der hier abgebildeten auf einfaches VerstÃ¤ndnis optimierten Form je nach Anwendung noch optimiert werden kann:
* Wenn im obigen Algorithmus zuerst die beiden HÃ¤lften des Feldes miteinander vertauscht werden, und dann die beiden HÃ¤lften dieser HÃ¤lften, usw. â€“ dann ist das Ergebnis am Ende dasselbe, wie wenn alle Elemente des Felds von 0 aufsteigend nummeriert werden - und dann die Reihenfolge der Bits der Nummern der Felder umgekehrt wird.
* Nachdem die Eingangswerte solchermaÃŸen umsortiert sind, bleibt nur noch die Aufgabe, die einzelnen kurzen FFTs von der letzten Rekursionsebene nach auÃŸen zu lÃ¤ngeren FFTs zu kombinieren, z.&amp;nbsp;B. in Form dreier ineinandergeschachtelter Schleifen:
** Die Ã¤uÃŸerste Schleife zÃ¤hlt die Rekursionsebene &lt;math>\mathit{Ebene}&lt;/math> durch (von 0 bis ''N-1'').
** Die nÃ¤chste Schleife zÃ¤hlt die &lt;math>2^{N-\mathrm{Ebene}-1}&lt;/math> FFT-Abschnitte durch, in der die FFT in dieser Rekursionsebene noch aufgeteilt ist. Der ZÃ¤hler dieser Schleife wird im Folgenden als â€ž&lt;math>\mathit{Abschnitt}&lt;/math>â€œ bezeichnet.
** Die innerste Schleife zÃ¤hlt das Element innerhalb eines FFT-Abschnittes (im Folgenden &lt;math>\mathit{ElementDesAbschnitts}&lt;/math> genannt) durch (von 0 bis &lt;math>2^{\mathrm{Ebene}}-1&lt;/math>)
** In der innersten dieser Schleifen werden nun immer die beiden Samples mit den folgenden beiden Indizes:

::&lt;math>\scriptstyle links=2^{\mathrm{Ebene}+1}\cdot\mathrm{Abschnitt}+\mathrm{ElementDesAbschnitts}&lt;/math>

::&lt;math>rechts=links+2^{\mathrm{Ebene}}&lt;/math>

:Ã¼ber einen [[Schmetterlingsgraph]] kombiniert: 
::&lt;math>
\begin{array}{rcl}
x_{\mathrm{links,neu}}&amp;=&amp;x_{\mathrm{rechts}}-e^{-i\pi\frac{\mathrm{ElementDesAbschnitts}}{\mathrm{2^{\mathrm{Ebene}}}}}\cdot x_{\mathrm{links}}\\
x_{\mathrm{rechts,neu}}&amp;=&amp;x_{\mathrm{rechts}}+e^{-i\pi\frac{\mathrm{ElementDesAbschnitts}}{\mathrm{2^{\mathrm{Ebene}}}}}\cdot x_{\mathrm{links}}\end{array}
&lt;/math>
*

== Alternative Formen der FFT ==
Neben dem oben dargestellten FFT-Algorithmus von Cooley und Tukey, auch Radix-2-Algorithmus genannt, existieren noch eine Reihe weiterer Algorithmen zur schnellen Fourier-Transformation. Die Varianten unterscheiden sich darin, wie bestimmte Teile des â€žnaivenâ€œ Algorithmus so umgeformt werden, dass weniger (HochprÃ¤zisions-)Multiplikationen notwendig sind. Dabei gilt meist, dass die Reduktion in der Anzahl der Multiplikationen eine erhÃ¶hte Anzahl von Additionen sowie von gleichzeitig im Speicher zu haltenden Zwischenergebnissen hervorruft.

Im Folgenden sind Ã¼bersichtsartig einige weitere Algorithmen dargestellt. Details und genaue mathematische Beschreibungen samt Herleitungen finden sich in der unten angegebenen Literatur. 

=== Radix-4-Algorithmus ===
Der Radix-4-Algorithmus ist, analog dazu der Radix-8-Algorithmus oder allgemein Radix-2&lt;sup>N&lt;/sup>-Algorithmus, eine Weiterentwicklung des obigen Radix-2-Algorithmus. Der Hauptunterschied besteht darin, dass die Anzahl der zu verarbeitenden Datenpunkte eine Potenz von 4 bzw. 4&lt;sup>N&lt;/sup> darstellen muss. Die Verarbeitungstruktur bleibt dabei gleich, nur dass in dem [[Schmetterlingsgraph]] pro Element statt zwei Datenpfade vier bzw. acht und allgemein 4&lt;sup>N&lt;/sup> Datenpfade miteinander verknÃ¼pft werden mÃ¼ssen. Der Vorteil besteht in einem weiter reduzierten Rechenaufwand und damit Geschwindigkeitsvorteil. So sind, verglichen mit dem obigen Algorithmus von Cooley und Tukey, bei dem Radix-4-Algorithmus ca. 25 % weniger Multiplikationen notwendig. Bei dem Radix-8-Algorithmus reduziert sich die Anzahl der Multiplikationen um ca. 40 %.

Nachteil dieser Verfahren ist die grÃ¶bere Struktur und ein aufwendiger Programmcode. So lassen sich mit Radix-4-Algorithmus nur BlÃ¶cke der LÃ¤ngen 4, 16, 64, 256, 1024, 4096, â€¦ verarbeiten. Bei dem Radix-8-Algorithmus sind die EinschrÃ¤nkungen analog zu sehen. WÃ¤re in einer bestimmten Anwendung eine BlocklÃ¤nge von beispielsweise 2048 StÃ¼tzstellen ideal und damit auch der Speicherplatz gering zu halten, kÃ¶nnen diese schnelleren Algorithmen daher nicht eingesetzt werden. Es mÃ¼sste dann ein grÃ¶ÃŸerer Speicher eingesetzt werden und der Rechenaufwand gesteigert werden.

=== Winograd-Algorithmus ===
Bei diesem Algorithmus ist nur eine bestimmte, endliche Anzahl von StÃ¼tzstellen der Anzahl &lt;math>N&lt;/math> mÃ¶glich, nÃ¤mlich:

:&lt;math>N = \prod^{m}_{j=1}N_j \qquad N_j \in \{2,3,4,5,7,8,9,16\}&lt;/math>

wobei alle Kombinationen von N&lt;sub>j&lt;/sub> zulÃ¤ssig sind, bei denen die verwendeten N&lt;sub>j&lt;/sub> [[Teilerfremdheit|teilerfremd]] sind. Dadurch ist nur eine maximale BlocklÃ¤nge von 5040 mÃ¶glich. Die mÃ¶glichen Werte fÃ¼r &lt;math>N&lt;/math> liegen aber in dem Bereich bis 5040 dichter auf der Zahlengeraden als die Zweierpotenzen. Es ist damit eine bessere Feinabstimmung der BlocklÃ¤nge mÃ¶glich. Aufgebaut wird der Algorithmus aus BasisblÃ¶cken der DFT, deren LÃ¤ngen mit ''N''&lt;sub>j&lt;/sub> korrespondieren. Bei diesem Verfahren wird zwar die Anzahl der Multiplikationen gegenÃ¼ber dem Radix-2-Algorithmus reduziert, gleichzeitig steigt aber die Anzahl der notwendigen Additionen. AuÃŸerdem ist am Eingang ''und'' Ausgang jeder DFT eine aufwendige Permutation der Daten notwendig, die nach den Regeln des [[Chinesischer Restsatz|Chinesischen Restsatzes]] gebildet wird. 

Diese Art der schnellen Fourier-Transformation besitzt in praktischen Implementierungen dann Vorteile gegenÃ¼ber der Radix-2-Methode, wenn der fÃ¼r die FFT verwendete [[Mikrocontroller]] keine eigene [[Multiplizierer (Digitaltechnik)|Multipliziereinheit]] besitzt und fÃ¼r die Multiplikationen sehr viel Rechenzeit aufgewendet werden muss. In heutigen [[Digitaler Signalprozessor|Signalprozessoren]] mit eigenen Multipliziereinheiten hat dieser Algorithmus keine wesentliche Bedeutung mehr.

=== Primfaktor-Algorithmus ===
Dieser FFT-Algorithmus basiert auf Ã¤hnlichen Ideen wie der Winograd-Algorithmus, allerdings ist die Struktur einfacher und damit der Aufwand an Multiplikationen hÃ¶her als beim Winograd-Algorithmus. Der wesentliche Vorteil bei der Implementierung liegt in der effizienten Ausnutzung des zur VerfÃ¼gung stehenden Speichers durch optimale Anpassung der BlocklÃ¤nge. Wenn in einer bestimmten Anwendung zwar eine schnelle Multipliziereinheit verfÃ¼gbar ist und gleichzeitig der Speicher knapp, kann dieser Algorithmus optimal sein. Die AusfÃ¼hrungszeit ist bei Ã¤hnlicher BlocklÃ¤nge mit der des Algorithmus von Cooley und Tukey vergleichbar.

=== Goertzel-Algorithmus ===
Der [[Goertzel-Algorithmus]] stellt eine besondere Form zur effizienten Berechnung einzelner Spektralkomponenten dar und ist bei der Berechnung von nur einigen wenigen Spektralanteilen (engl. ''Bins'') effizienter als alle blockbasierenden FFT-Algorithmen, welche immer das komplette diskrete Spektrum berechnen.

=== Chirp-z-Transformation ===
[[Bluestein-FFT-Algorithmus]] fÃ¼r Datenmengen beliebiger GrÃ¶ÃŸe (einschlieÃŸlich [[Primzahl]]en).

== Interpretation der Ergebnisse ==
=== Allgemein ===
Die FFT generiert aus ''n'' komplexen Eingangswerten ''n'' komplexe Ergebniswerte.

Der Betrag jedes dieser Ausgangswerte entspricht der LÃ¤nge, und das Argument jedes Ausgangswerts dem Winkel eines Vektors zum Zeitpunkt ''t=0''. Wenn man nun alle Vektoren mit den richtigen Geschwindigkeiten um den Nullpunkt kreisen lÃ¤sst, - und sie zueinander addiert, erhÃ¤lt man wieder die Eingangswerte. 

Die Frequenz, mit der der ''m''-te Vektor des errechneten Spektrums dafÃ¼r gegen den Uhrzeigersinn gedreht werden muss, ergibt sich durch die Formel
:&lt;math>f_{\mathrm{Drehung}}=\left\{\begin{array}{ll}
f_{\mathrm{Sample}}\cdot \frac{m}{n}&amp;;\ m\leq\frac{n}{2}\\[.5em]
f_{\mathrm{Sample}}\cdot \frac{n-m}{n}&amp;;\ m>\frac{n}{2}
\end{array}\right.&lt;/math>

Vektoren mÃ¼ssen sich also mit einer um so hÃ¶heren Frequenz drehen, je nÃ¤her sie zur Mitte des Ergebnisses der FFT liegen, und jeder Vektor aus der oberen HÃ¤lfte des Ergebnisses dreht sich mit derselben Frequenz, aber in die umgekehrte Richtung, wie ein Vektor aus der unteren HÃ¤lfte des Ergebnisses dies tut. Zu erklÃ¤ren ist dies beispielsweise Ã¼ber das [[Nyquist-Shannon-Abtasttheorem]], das besagt, dass Frequenzen Ã¼ber der halben Abtastfrequenz durch die Abtastung in den Frequenzbereich darunter gespiegelt werden; Zu beachten ist, dass aus zwei sich in unterschiedlicher Richtung, aber mit der gleichen Geschwindigkeit drehenden Vektoren alle Kreisbewegungen, Elliptischen Bewegungen, Sinus- oder Kosinusschwingungen mit der entsprechenden Frequenz zusammengesetzt werden kÃ¶nnen.

=== FÃ¼r Eingangsdaten ohne ImaginÃ¤rteil ===
[[File:Fftsymreal.png|thumb|250px|Acht-Punkt FFT auf reellen Eingangsdaten]]
Damit aus den beiden mit derselben Frequenz kreisenden Vektoren ein Signal mit dem ImaginÃ¤rteil 0 zusammengesetzt werden kann, muss der Realteil der beiden mit derselben Frequenz rotierenden Vektoren identisch sein, - und mÃ¼ssen die beiden ImaginÃ¤rteile der Vektoren zusammen stets Null ergeben.

Hieraus folgt:
:&lt;math>\left.\begin{array}{rcr}
\mathrm{Re}(f_m)&amp;=&amp;\mathrm{Re}(f_{n-m})\\
\mathrm{Img}(f_m)&amp;=&amp;-\mathrm{Img}(f_{n-m})
\end{array}\right\}\ \Longrightarrow\ f_m=f_{n-m}^*&lt;/math>

Ist bekannt, dass das Eingangssignal der FFT rein reell war, lohnt es sich daher nur, eine (im Regelfall die untere) HÃ¤lfte des Spektrums zu betrachten, wo der Betrag jedes Vektors der halben Amplitude einer Frequenz, und das Argument jedes Vektors der Phasenverschiebung einer Frequenz entspricht, aus der sich das Eingangssignal zusammensetzt.

Besondere Beachtung verdienen allenfalls in einigen FÃ¤llen der Gleichanteil, und das Element, das der hÃ¶chsten im errechneten Spektrum mÃ¶glichen Frequenz entspricht.

=== Genauigkeit ===
Tendenziell ist das Quantisierungsrauschen bei der schnellen Fouriertransformation in den FÃ¤llen, in denen sie effektiver als die DFT ist, aufgrund der geringeren Zahl an fehlerbehafteten Rechenoperationen geringer&lt;ref>[http://www.dspguide.com/ch18.htm ''Steven W. Smith, Ph.D.'' The Scientist and Engineer's Guide to Digital Signal Processing]. Buch in der Online-Ausgabe. Abgerufen am 8. Dezember 2009.&lt;/ref> als bei der diskreten Faltung.

== Die inverse FFT ==
Die enge Verwandtschaft zwischen FFT und [[iFFT]] lÃ¤sst sich bereits aufgrund der folgenden Ãœberlegungen erahnen:
* Ist das Eingangssignal der FFT ein mit einer konstanten Geschwindigkeit um den Nullpunkt rotierender Vektor, dann ist das Ergebnis der FFT bestimmungsgemÃ¤ÃŸ ein Ausgangssignal, das bis auf den der Frequenz der Rotation entsprechenden Punkt, dessen Betrag der Amplitude und dessen Argument der Phase der Rotation zum Zeitpunkt ''t=0'' entspricht â€“ konstant 0.
* Ist das Eingangssignal der FFT konstant 0 mit Ausnahme eines einzigen Punktes, so ergibt die Grundgleichung der DFT in diesem Fall einen Vektor, der mit einer konstanten Geschwindigkeit um den Nullpunkt kreist.
FÃ¼r einen Vektor, in dem nur ein einziger Punkt eine Amplitude ungleich 0 besitzt, Ã¤hnelt also die zweimalige FFT des Ergebnisses dem Ausgangswert.
* ZusÃ¤tzlich besteht die FFT nur aus linearen Gleichungen. Dies bedeutet unter Anderem, dass, wenn verschiedene Ausgangsvektoren addiert und dann zwei Mal durch die FFT transformiert werden, das Ergebnis dieser Aktion identisch sein muss, wie, wenn die einzelnen Signale erst zweimal transformiert und dann addiert werden.
Zusammen lÃ¤sst dies vermuten, dass das Ergebnis einer zweimal hintereinander ausgefÃ¼hrten FFT fÃ¼r beliebige Signale dem Original Ã¤hneln wird.

Allerdings ist die Amplitude des Ergebnisses der zweimaligen FFT eines Signals offensichtlich von dessen LÃ¤nge &lt;math>L&lt;/math> abhÃ¤ngig, und ist in den obigen Ãœberlegungen die Richtung der Rotation der Vektoren um den Nullpunkt nicht berÃ¼cksichtigt worden.

TatsÃ¤chlich gilt fÃ¼r jegliche Art der Fouriertransformation:

:&lt;math>\frac{1}{\mathrm{L}}\left(\mathcal{F}\left\{\left(\mathcal{F}\left\{f(x)\right\}\right)^*\right\}\right)^*=f(x)&lt;/math>

== Anwendung ==
Die Anwendungsgebiete der FFT sind so vielseitig, dass hier nur eine Auswahl gegeben werden kann:
* [[Computeralgebra]]
** Implementierung schneller, Polynome verarbeitender Algorithmen (z.&amp;nbsp;B. Polynommultiplikation in &lt;math>O(n\, \log{n})&lt;/math>)
* Finanzmathematik
** Die Berechnung von Optionspreisen (vgl. Carr / Madan 1999)
* [[Signalanalyse]]
** Akustik (Audiomessungen). Eine triviale Anwendung sind viele Gitarrenstimm- oder Ã¤hnliche Programme, die von ihrer hohen Geschwindigkeit profitieren.
** Berechnung vom [[Spektrogramm]]en (Diagramme mit der Darstellung der Amplituden von den jeweiligen Frequenzanteilen)
** Rekonstruktion des Bildes beim [[Kernspintomograph]]en oder der Analyse von Kristallstrukturen mittels RÃ¶ntgenstrahlen, bei denen jeweils die Fouriertransformierte des gewÃ¼nschten Bildes, bzw. das Quadrat dieser Fouriertransformierten entsteht.
* Messtechnik/ allgemein
** Digitale Netzwerkanalysatoren, die das Verhalten einer Schaltung, eines Bauelementes oder einer Leitung auf einer Leiterbahn bei Betrieb mit beliebigen Frequenzgemischen zu ermitteln versuchen.
* Signalverarbeitung
** Synthese von Audiosignalen aus einzelnen Frequenzen Ã¼ber die inverse FFT
** Zur Reduzierung des Berechnungsaufwandes bei der zirkularen Faltung im [[Zeitbereich]] von [[Filter mit endlicher Impulsantwort|FIR-Filtern]] und Ersatz durch die schnelle Fouriertransformation und einfache Multiplikationen im [[Frequenzspektrum|Frequenzbereich]]. (siehe auch [[Schnelle Faltung]]). Die Schnelle Faltung bietet z.&amp;nbsp;B. die MÃ¶glichkeit, beliebige Audio- oder Ã¤hnliche Signale mit wenig Rechenaufwand durch auch sehr komplexe Filter (Equalizer, etc.) zu transportieren.
** [[Kompressionsalgorithmus|Kompressionsalgorithmen]] verwenden oft die FFT oder, wie das bekannte [[MP3]]-Format, die mit ihr verwandte [[diskrete Kosinustransformation]]: Die FFT von Bildern oder TÃ¶nen ergibt oft nur relativ wenige Frequenzanteile mit hohen Amplituden (Was, wenn ein Verfahren zur Speicherung der Ergebnisse verwendet wird, das fÃ¼r die Darstellung niedriger Zahlen weniger Bits benÃ¶tigt, wie z.&amp;nbsp;B. die [[Huffman-Kodierung]], von Vorteil ist). In anderen FÃ¤llen wird ausgenutzt, dass einige der Frequenzen weggelassen werden kÃ¶nnen, ohne das Ergebnis stark zu beeintrÃ¤chtigen, so dass die Menge der zu speichernden Daten auf diese Weise reduziert werden kann.
* Telekommunikation
** [[LÃ¤ngstwellen]]empfang mit dem PC
** BreitbanddatenÃ¼bertragung per [[OFDM]], die Grundlage fÃ¼r [[ADSL]] und [[WLAN]] (Internet), [[DVB-T]] (Fernsehen), [[Digital Radio Mondiale|DRM]], [[Digital Audio Broadcasting|DAB]] (Radio) und [[Long_Term_Evolution|LTE]] (Mobilfunk der 4. Generation) ist. Hier wird die hohe Geschwindigkeit dadurch erreicht, dass viele relativ langsame DatenÃ¼bertragungen auf vielen TrÃ¤gerfrequenzen gleichzeitig betrieben werden. Das komplexe Signal, das durch Ãœberlagerung der einzelnen Signale entsteht, wird dann von der Gegenstelle mittels der FFT wieder in einzelne SignaltrÃ¤ger zerlegt.

== Literatur ==
=== Zeitschriftenartikel ===
&lt;!--(historische bedeutende)-->
* James W. Cooley, John W. Tukey: ''An algorithm for the machine calculation of complex Fourier series.'' In: ''Math. Comput.'' 19, 1965, S. 297â€“301.
* C. M. Rader: ''Discrete Fourier transforms when the number of data samples is prime.'' In: ''Proc. IEEE.'' 56, 1968, S. 1107â€“1108.
* Leo I. Bluestein: ''A linear filtering approach to the computation of the discrete Fourier transform.'' In: ''Northeast Electronics Research and Engineering Meeting Record.'' 10, 1968, S. 218â€“219.
* Georg Bruun: ''z-Transform DFT filters and FFTs.'' In: ''IEEE Trans. on Acoustics, Speech and Signal Processing (ASSP).'' 26, Nr. 1, 1978, S. 56â€“63.
* M. T. Heideman, D. H. Johnson, C. S. Burrus : ''Gauss and the History of the Fast Fourier Transform.'' In: ''Arch. Hist. Sc.'' 34, Nr. 3, 1985.&lt;!-- Zuvor schon in IEEE Acoust. Speech Signal Process. Mag. Oktober 1984 verÃ¶ffentlicht? -->
=== BÃ¼cher ===
* Alan V. Oppenheim, Ronald W. Schafer: ''Zeitdiskrete Signalverarbeitung.'' 3. Auflage. R. Oldenbourg Verlag, MÃ¼nchen/Wien 1999, ISBN 3-486-24145-1.
* E. Oran Brigham: ''FFT. Schnelle Fourier-Transformation.'' R. Oldenbourg Verlag, MÃ¼nchen/Wien 1995, ISBN 3-486-23177-4.
* {{Literatur
 |Autor = Steven W. Smith
 |Titel = The Scientist and Engineer's Guide to Digital Signal Processing
 |Verlag = Elsevier Ltd, Oxford |Jahr = 2002 |Auflage = 1 |Kapitel = 18 |ISBN = 978-0750674447 | Online = [http://www.dspguide.com www.dspguide.com] |Originalsprache= Englisch
}}

== Weblinks ==
* [http://www.inf.fh-flensburg.de/lang/algorithmen/fft/fft.htm www.inf.fh-flensburg.de/lang/algorithmen/fft/fft.htm] â€“ Beschreibung der Fourier-Transformation und Einheitswurzeln (Deutsch)
* [http://www.fairaudio.de/hifi-lexikon-begriffe/fourier-transformation.html] â€“ Bedeutung der FFT-Analyse in der Audiotechnik (Beispiel-Grafik: Rechtecksignal) (Deutsch)
* [http://www.sprut.de/electronic/pic/16bit/dsp/fft/fft.htm www.sprut.de/electronic/pic/16bit/dsp/fft/fft.htm] â€“ EinfÃ¼hrung in die FFT fÃ¼r Nichtstudierte, z.&amp;nbsp;B. Auszubildende (Deutsch)
* [http://www.fftw.org/ www.fftw.org] (Englisch)
* [http://www.nr.com/ www.nr.com] â€“ Buch ''Numerical Recipes'', englisch, auch online verfÃ¼gbar (Englisch)
* [http://paulbourke.net/miscellaneous/dft/ Paul Bourke (1993):''D F T (Discrete Fourier Transform) - F F T (Fast Fourier Transform)''] (schÃ¶ner FFT-Code in C, in 1D und 2D) (Englisch)
* {{Internetquelle|autor = Kevin McGee |titel = An introduction to signal processing and fast fourier transform (FFT) |url=http://www.fftguru.com |zugriff=2010-04-27}}

== Einzelnachweise ==
&lt;references />

[[Kategorie:Numerische Mathematik]]
[[Kategorie:Digitale Signalverarbeitung]]
[[Kategorie:Diskrete Transformation]]

[[ar:ØªØ­ÙˆÙŠÙ„ Ù?ÙˆØ±ÙŠÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹]]
[[ca:Transformada RÃ pida de Fourier]]
[[cs:RychlÃ¡ Fourierova transformace]]
[[da:Fast Fourier Transform]]
[[en:Fast Fourier transform]]
[[es:Transformada rÃ¡pida de Fourier]]
[[fa:ØªØ¨Ø¯ÛŒÙ„ Ø³Ø±ÛŒØ¹ Ù?ÙˆØ±ÛŒÙ‡]]
[[fr:TransformÃ©e de Fourier rapide]]
[[he:FFT]]
[[hi:à¤¤à¥?à¤µà¤°à¤¿à¤¤ à¤«à¥?à¤°à¤¿à¤…à¤° à¤°à¥‚à¤ªà¤¾à¤¨à¥?à¤¤à¤°]]
[[id:Transformasi Fourier cepat]]
[[it:Trasformata di Fourier veloce]]
[[ja:é«˜é€Ÿãƒ•ãƒ¼ãƒªã‚¨å¤‰æ?›]]
[[ko:ê³ ì†? í‘¸ë¦¬ì—? ë³€í™˜]]
[[nl:Fast Fourier transform]]
[[pl:Szybka transformacja Fouriera]]
[[pt:Transformada rÃ¡pida de Fourier]]
[[ru:Ð‘Ñ‹Ñ?Ñ‚Ñ€Ð¾Ðµ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¤ÑƒÑ€ÑŒÐµ]]
[[sr:Ð‘Ñ€Ð·Ð° Ð¤ÑƒÑ€Ð¸Ñ˜ÐµÐ¾Ð²Ð° Ñ‚Ñ€Ð°Ð½Ñ?Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ˜Ð°]]
[[sv:Snabb fouriertransform]]
[[ta:à®µà®¿à®°à¯ˆà®µà¯? à®ƒà®ªà¯‚à®°à®¿à®¯à¯‡ à®‰à®°à¯?à®®à®¾à®±à¯?à®±à®®à¯?]]
[[tr:HÄ±zlÄ± Fourier dÃ¶nÃ¼ÅŸÃ¼mÃ¼]]
[[uk:Ð¨Ð²Ð¸Ð´ÐºÐµ Ð¿ÐµÑ€ÐµÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ? Ð¤ÑƒÑ€'Ñ”]]
[[vi:Biáº¿n Ä‘á»•i Fourier nhanh]]
[[zh:å¿«é€Ÿå‚…é‡Œå?¶å?˜æ?¢]]
